{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c5e70c3",
   "metadata": {},
   "source": [
    "# ğŸ§  LLM Research Agent - Pipeline\n",
    "This notebook runs your Research Agent to fetch and summarize latest papers from arXiv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "058f8f34",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'memory'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m sys.path.append(os.path.abspath(\u001b[33m\"\u001b[39m\u001b[33msrc\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmemory\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory_manager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MemoryManager\n\u001b[32m      6\u001b[39m memory = MemoryManager()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'memory'"
     ]
    }
   ],
   "source": [
    "# Load FAISS memory manager\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "\n",
    "from memory.memory_manager import MemoryManager\n",
    "memory = MemoryManager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d3a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Set up import path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c79524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Krish\\OneDrive\\Desktop\\ResumeProjects\\llm-agent-toolformer-project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# ğŸ‘‡ This adds the full absolute path to the `src` folder\n",
    "sys.path.append(\"C:/Users/Krish/OneDrive/Desktop/ResumeProjects/llm-agent-toolformer-project/src\")\n",
    "\n",
    "from agents.research_agent import run_research_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702b39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” Define your research query here\n",
    "query = \"Graph RAG\"\n",
    "max_results = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c55fde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] Starting research on: Graph RAG\n",
      "[Agent] Summarizing paper 1: On cycle covers of infinite bipartite graphs\n",
      "[Agent] Summarizing paper 2: Vertex-Based Localization of TurÃ¡n's Theorem\n",
      "[Agent] Summarizing paper 3: MENA: Multimodal Epistemic Network Analysis for Visualizing Competencies and Emotions\n",
      "[Agent] âœ… Results saved to: C:\\Users\\Krish\\OneDrive\\Desktop\\ResumeProjects\\llm-agent-toolformer-project\\data\\research_Graph_RAG_2025-04-05_16-12-02.json\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ Run the agent\n",
    "results = run_research_agent(query, max_results=max_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e27a33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¹ 1. On cycle covers of infinite bipartite graphs\n",
      "\n",
      "ğŸ“„ Summary: a bipartite graph $G$ with sides $A$ and $B$ satisfies the double Hall property if for every subset $X$ of vertices . $N2_G(X)vert geq ver Xvert$ exists a cycle in $ G$ that covers all vertics of $ A$ . the conjecture is false for infinite graphs in general .\n",
      "\n",
      "ğŸ”— URL: http://arxiv.org/abs/2504.02816v1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ”¹ 2. Vertex-Based Localization of TurÃ¡n's Theorem\n",
      "\n",
      "ğŸ“„ Summary: theorem states that in a simple $K_r+1$ free graph, $m leq fracn2(r-1)2r$ . for each $v in V(G)$, let $c(v)$ be the order of the largest clique that contains $v$.\n",
      "\n",
      "ğŸ”— URL: http://arxiv.org/abs/2504.02806v1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ”¹ 3. MENA: Multimodal Epistemic Network Analysis for Visualizing Competencies and Emotions\n",
      "\n",
      "ğŸ“„ Summary: simulated trainings can boost competencies, but extracting meaningful insights from these practices remains a challenge . MENA enhances the capabilities of Epistemic Network Analysis by detecting positive emotions, enabling visualization and analysis of complex relationships between caregiving competencies and emotions in dynamic caregiving practices .\n",
      "\n",
      "ğŸ”— URL: http://arxiv.org/abs/2504.02794v1\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“„ Display results\n",
    "for i, paper in enumerate(results):\n",
    "    print(f\"\\nğŸ”¹ {i+1}. {paper['title']}\\n\")\n",
    "    print(f\"ğŸ“„ Summary: {paper['summary']}\\n\")\n",
    "    print(f\"ğŸ”— URL: {paper['url']}\\n\")\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f8316b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Files saved in data/:\n",
      " - research_Graph_RAG_2025-04-05_13-02-57.json\n",
      " - research_Graph_RAG_2025-04-05_15-58-34.json\n",
      " - research_Graph_RAG_2025-04-05_16-03-43.json\n",
      " - research_Graph_RAG_2025-04-05_16-05-12.json\n",
      " - research_Graph_RAG_2025-04-05_16-09-13.json\n",
      " - research_Graph_RAG_2025-04-05_16-12-02.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"\\nğŸ“ Files saved in data/:\")\n",
    "for f in os.listdir(\"../data\"):\n",
    "    print(\" -\", f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc0b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "\n",
    "from tools.pdf_reader import extract_pdf_text\n",
    "from tools.summarizer import summarize_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d202bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with your actual PDF path (relative to notebook or absolute)\n",
    "pdf_path = \"../sample_docs/HTF Mystery Book.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29cb467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PDF text extracted!\n",
      "Book Provided Buy @GroupBuys_Bot \n",
      " \n",
      "F L I P P I N G M A R K E T S \n",
      "HIGHER TIMEFRAME \n",
      "M Y S T E R Y \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "The strategy that will \n",
      "help you to escape the \n",
      "9-5 SLAVERY \n",
      "Book Provided Buy @GroupBuys_Bot \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Welcome to a transformative journey into the world of forex trading, where \n",
      "you'll discover a strategy designed to fit seamlessly into your life, whether \n",
      "you're a seasoned trader or just starting out. \n",
      "This book aims to empower you with tools and insights that will \n",
      "revolutionize your trading experience, making it more efficient, less \n",
      "stressful, and ultimately more profitable. \n",
      " \n",
      "If I had to highlight a few parts of this strategy, here are some things that \n",
      "make it brilliant: \n",
      " \n",
      "Reduced Chart Anxiety \n",
      " \n",
      "One of the primary obstacles many traders face is the overwhelming \n",
      "anxiety that comes with constantly monitoring charts and making rapid \n",
      "decisions. This book introduces techniques to reduce chart anxiety, \n",
      "enabling quicker decision-making and boosting your confidence.\n"
     ]
    }
   ],
   "source": [
    "# Extract text\n",
    "pdf_text = extract_pdf_text(pdf_path)\n",
    "print(\"âœ… PDF text extracted!\")\n",
    "\n",
    "# Optional preview\n",
    "print(pdf_text[:1000])  # preview first 1000 characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b93d0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Summary:\n",
      " book Provided Buy @GroupBuys_Bot Welcome to a transformative journey into the world of forex trading . aims to empower you with tools and insights that will revolutionize your trading experience .\n"
     ]
    }
   ],
   "source": [
    "# You can chunk if needed, but for now:\n",
    "summary = summarize_text(pdf_text[:1000])  # summarizing the preview\n",
    "print(\"ğŸ“ Summary:\\n\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d19eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "\n",
    "from tools.web_search import web_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43438b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # ğŸ‘ˆ loads variables from .env\n",
    "\n",
    "SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a413a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Latest research on Graph RAG\"\n",
    "\n",
    "results = web_search(query, api_key=SERPER_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b01093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ 1. Welcome - GraphRAG\n",
      "ğŸ“„ GraphRAG uses knowledge graphs to provide substantial improvements in question-and-answer performance when reasoning about complex information. RAG techniques ...\n",
      "ğŸ”— https://microsoft.github.io/graphrag/\n",
      "\n",
      "ğŸ”¹ 2. Project GraphRAG: News & features - Microsoft Research\n",
      "ğŸ“„ Redmond opens up to discuss its new tool, which can extract data from unstructured text using large language models. Microsoft's GraphRAG is a new approach to ...\n",
      "ğŸ”— https://www.microsoft.com/en-us/research/project/graphrag/news-and-awards/\n",
      "\n",
      "ğŸ”¹ 3. Graph RAG Explained - by Nir Diamant - DiamantAI\n",
      "ğŸ“„ Graph RAG fixes the limits of regular RAG by finding nodes and edges from a knowledge graph â€“ in other words, a web of facts and their links.\n",
      "ğŸ”— https://diamantai.substack.com/p/graph-rag-explained\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if isinstance(results, list):\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"ğŸ”¹ {i}. {r['title']}\")\n",
    "        print(f\"ğŸ“„ {r['snippet']}\")\n",
    "        print(f\"ğŸ”— {r['link']}\\n\")\n",
    "else:\n",
    "    print(results)  # In case of error string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8828342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "\n",
    "from tools.wiki_lookup import wiki_lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d4696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Wikipedia Summary:\n",
      " Prompt engineering is the process of structuring or crafting an instruction in order to produce the best possible output from a generative artificial intelligence (AI) model.\n",
      "A prompt is natural language text describing the task that an AI should perform. A prompt for a text-to-text language model can be a query, a command, or a longer statement including context, instructions, and conversation history.\n"
     ]
    }
   ],
   "source": [
    "query = \"Graph RAG\"\n",
    "\n",
    "wiki_summary = wiki_lookup(query, sentences=3)\n",
    "print(\"ğŸ“ Wikipedia Summary:\\n\", wiki_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e13e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.tool_selector import tool_selector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fef4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Source: Wikipedia\n",
      "ğŸ“ Result:\n",
      "Prompt engineering is the process of structuring or crafting an instruction in order to produce the best possible output from a generative artificial intelligence (AI) model.\n",
      "A prompt is natural language text describing the task that an AI should perform. A prompt for a text-to-text language model can be a query, a command, or a longer statement including context, instructions, and conversation history.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 120, but your input_length is only 32. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ Advancements in RAG: A Comprehensive Survey of Techniques ...\n",
      "ğŸ“„ Recent Advances in Retrieval Techniques Â· Query Optimization Â· Embedding Models Â· Retrieval Sources and Granularity Â· Indexing Optimization ...\n",
      "ğŸ”— https://medium.com/@sahin.samia/advancements-in-rag-a-comprehensive-survey-of-techniques-and-applications-b6160b035199\n",
      "\n",
      "ğŸ”¹ Top 10 RAG Papers from January 2025 - Athina AI Hub\n",
      "ğŸ“„ Top 10 RAG Papers from January 2025 Â· 1) Retrieval-Augmented Generation with Graphs (GraphRAG) Â· 2) MiniRAG: Towards Extremely Simple Retrieval- ...\n",
      "ğŸ”— https://hub.athina.ai/top-10-rag-papers-from-january-2025-2/\n",
      "\n",
      "ğŸ”¹ Latest Developments in Retrieval-Augmented Generation - CelerData\n",
      "ğŸ“„ RAG combines two powerful elements: retrieval mechanisms and generative models. This combination enhances the quality and relevance of generated content.\n",
      "ğŸ”— https://celerdata.com/glossary/latest-developments-in-retrieval-augmented-generation\n",
      "\n",
      "ğŸ“„ PDF Summary:\n",
      "[PDF Reader Error] no such file: '../sample_docs/semple.pdf'\n"
     ]
    }
   ],
   "source": [
    "# Wiki\n",
    "res1 = tool_selector(\"Graph RAG\", context_type=\"wiki\")\n",
    "print(f\"ğŸ“˜ Source: {res1['source']}\\nğŸ“ Result:\\n{res1['result']}\\n\")\n",
    "\n",
    "# Web\n",
    "res2 = tool_selector(\"Latest RAG breakthroughs\", context_type=\"web\", api_keys={\"SERPER_API_KEY\": SERPER_API_KEY})\n",
    "if isinstance(res2[\"result\"], list):\n",
    "    for r in res2[\"result\"]:\n",
    "        print(f\"ğŸ”¹ {r['title']}\\nğŸ“„ {r['snippet']}\\nğŸ”— {r['link']}\\n\")\n",
    "\n",
    "# PDF\n",
    "res3 = tool_selector(\"N/A\", context_type=\"pdf\", file_path=\"../sample_docs/sample.pdf\")\n",
    "print(f\"ğŸ“„ PDF Summary:\\n{res3['result']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1ab68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Graph RAG is a combination of retrieval-augmented generation and graph reasoning.\n",
      "2. Graph RAG is a combination of retrieval-augmented generation and graph reasoning.\n",
      "3. Graph RAG is a combination of retrieval-augmented generation and graph reasoning.\n"
     ]
    }
   ],
   "source": [
    "from memory.memory_manager import MemoryManager\n",
    "\n",
    "memory = MemoryManager()\n",
    "\n",
    "# Add something\n",
    "memory.add_memory(\"Graph RAG is a combination of retrieval-augmented generation and graph reasoning.\")\n",
    "\n",
    "# Retrieve\n",
    "results = memory.search_memory(\"What is Graph RAG?\")\n",
    "for i, r in enumerate(results, 1):\n",
    "    print(f\"{i}. {r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69bd3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Found relevant memory:\n",
      "1. Graph RAG is a combination of retrieval-augmented generation and graph reasoning.\n",
      "\n",
      "2. Graph RAG is a combination of retrieval-augmented generation and graph reasoning.\n",
      "\n",
      "3. Graph RAG is a combination of retrieval-augmented generation and graph reasoning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from agents.tool_selector import tool_selector\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\")\n",
    "\n",
    "# ğŸ” User query\n",
    "user_query = \"Graph RAG applications in 2024\"\n",
    "\n",
    "# ğŸ§  1. Search memory\n",
    "context = memory.search_memory(user_query)\n",
    "\n",
    "# ğŸ› ï¸ 2. If memory insufficient, call tool\n",
    "if len(context) < 2:\n",
    "    response = tool_selector(user_query, context_type=\"wiki\", api_keys={\"SERPER_API_KEY\": SERPER_API_KEY})\n",
    "    print(f\"ğŸ” Using Tool: {response['source']}\")\n",
    "    print(f\"ğŸ“„ Result:\\n{response['result']}\\n\")\n",
    "    \n",
    "    memory.add_memory(response[\"result\"])\n",
    "else:\n",
    "    print(\"ğŸ§  Found relevant memory:\")\n",
    "    for i, mem in enumerate(context):\n",
    "        print(f\"{i+1}. {mem}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55202f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
