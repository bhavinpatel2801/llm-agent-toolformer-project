{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c5e70c3",
   "metadata": {},
   "source": [
    "# üß† LLM Research Agent - Pipeline\n",
    "This notebook runs your Research Agent to fetch and summarize latest papers from arXiv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "058f8f34",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'memory'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m sys.path.append(os.path.abspath(\u001b[33m\"\u001b[39m\u001b[33msrc\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmemory\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory_manager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MemoryManager\n\u001b[32m      6\u001b[39m memory = MemoryManager()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'memory'"
     ]
    }
   ],
   "source": [
    "# Load FAISS memory manager\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "\n",
    "from memory.memory_manager import MemoryManager\n",
    "memory = MemoryManager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d3a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Set up import path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c79524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Krish\\OneDrive\\Desktop\\ResumeProjects\\llm-agent-toolformer-project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# üëá This adds the full absolute path to the `src` folder\n",
    "sys.path.append(\"C:/Users/Krish/OneDrive/Desktop/ResumeProjects/llm-agent-toolformer-project/src\")\n",
    "\n",
    "from agents.research_agent import run_research_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702b39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Define your research query here\n",
    "query = \"Graph RAG\"\n",
    "max_results = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c55fde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] Starting research on: Graph RAG\n",
      "[Agent] Summarizing paper 1: On cycle covers of infinite bipartite graphs\n",
      "[Agent] Summarizing paper 2: Vertex-Based Localization of Tur√°n's Theorem\n",
      "[Agent] Summarizing paper 3: MENA: Multimodal Epistemic Network Analysis for Visualizing Competencies and Emotions\n",
      "[Agent] ‚úÖ Results saved to: C:\\Users\\Krish\\OneDrive\\Desktop\\ResumeProjects\\llm-agent-toolformer-project\\data\\research_Graph_RAG_2025-04-05_16-12-02.json\n"
     ]
    }
   ],
   "source": [
    "# üöÄ Run the agent\n",
    "results = run_research_agent(query, max_results=max_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e27a33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ 1. On cycle covers of infinite bipartite graphs\n",
      "\n",
      "üìÑ Summary: a bipartite graph $G$ with sides $A$ and $B$ satisfies the double Hall property if for every subset $X$ of vertices . $N2_G(X)vert geq ver Xvert$ exists a cycle in $ G$ that covers all vertics of $ A$ . the conjecture is false for infinite graphs in general .\n",
      "\n",
      "üîó URL: http://arxiv.org/abs/2504.02816v1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üîπ 2. Vertex-Based Localization of Tur√°n's Theorem\n",
      "\n",
      "üìÑ Summary: theorem states that in a simple $K_r+1$ free graph, $m leq fracn2(r-1)2r$ . for each $v in V(G)$, let $c(v)$ be the order of the largest clique that contains $v$.\n",
      "\n",
      "üîó URL: http://arxiv.org/abs/2504.02806v1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üîπ 3. MENA: Multimodal Epistemic Network Analysis for Visualizing Competencies and Emotions\n",
      "\n",
      "üìÑ Summary: simulated trainings can boost competencies, but extracting meaningful insights from these practices remains a challenge . MENA enhances the capabilities of Epistemic Network Analysis by detecting positive emotions, enabling visualization and analysis of complex relationships between caregiving competencies and emotions in dynamic caregiving practices .\n",
      "\n",
      "üîó URL: http://arxiv.org/abs/2504.02794v1\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# üìÑ Display results\n",
    "for i, paper in enumerate(results):\n",
    "    print(f\"\\nüîπ {i+1}. {paper['title']}\\n\")\n",
    "    print(f\"üìÑ Summary: {paper['summary']}\\n\")\n",
    "    print(f\"üîó URL: {paper['url']}\\n\")\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f8316b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Files saved in data/:\n",
      " - research_Graph_RAG_2025-04-05_13-02-57.json\n",
      " - research_Graph_RAG_2025-04-05_15-58-34.json\n",
      " - research_Graph_RAG_2025-04-05_16-03-43.json\n",
      " - research_Graph_RAG_2025-04-05_16-05-12.json\n",
      " - research_Graph_RAG_2025-04-05_16-09-13.json\n",
      " - research_Graph_RAG_2025-04-05_16-12-02.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"\\nüìÅ Files saved in data/:\")\n",
    "for f in os.listdir(\"../data\"):\n",
    "    print(\" -\", f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc0b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "\n",
    "from tools.pdf_reader import extract_pdf_text\n",
    "from tools.summarizer import summarize_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d202bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with your actual PDF path (relative to notebook or absolute)\n",
    "pdf_path = \"../sample_docs/HTF Mystery Book.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29cb467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PDF text extracted!\n",
      "Book Provided Buy @GroupBuys_Bot \n",
      " \n",
      "F L I P P I N G M A R K E T S \n",
      "HIGHER TIMEFRAME \n",
      "M Y S T E R Y \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "The strategy that will \n",
      "help you to escape the \n",
      "9-5 SLAVERY \n",
      "Book Provided Buy @GroupBuys_Bot \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Welcome to a transformative journey into the world of forex trading, where \n",
      "you'll discover a strategy designed to fit seamlessly into your life, whether \n",
      "you're a seasoned trader or just starting out. \n",
      "This book aims to empower you with tools and insights that will \n",
      "revolutionize your trading experience, making it more efficient, less \n",
      "stressful, and ultimately more profitable. \n",
      " \n",
      "If I had to highlight a few parts of this strategy, here are some things that \n",
      "make it brilliant: \n",
      " \n",
      "Reduced Chart Anxiety \n",
      " \n",
      "One of the primary obstacles many traders face is the overwhelming \n",
      "anxiety that comes with constantly monitoring charts and making rapid \n",
      "decisions. This book introduces techniques to reduce chart anxiety, \n",
      "enabling quicker decision-making and boosting your confidence.\n"
     ]
    }
   ],
   "source": [
    "# Extract text\n",
    "pdf_text = extract_pdf_text(pdf_path)\n",
    "print(\"‚úÖ PDF text extracted!\")\n",
    "\n",
    "# Optional preview\n",
    "print(pdf_text[:1000])  # preview first 1000 characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b93d0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Summary:\n",
      " book Provided Buy @GroupBuys_Bot Welcome to a transformative journey into the world of forex trading . aims to empower you with tools and insights that will revolutionize your trading experience .\n"
     ]
    }
   ],
   "source": [
    "# You can chunk if needed, but for now:\n",
    "summary = summarize_text(pdf_text[:1000])  # summarizing the preview\n",
    "print(\"üìù Summary:\\n\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d19eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "\n",
    "from tools.web_search import web_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43438b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # üëà loads variables from .env\n",
    "\n",
    "SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a413a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Latest research on Graph RAG\"\n",
    "\n",
    "results = web_search(query, api_key=SERPER_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b01093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ 1. Welcome - GraphRAG\n",
      "üìÑ GraphRAG uses knowledge graphs to provide substantial improvements in question-and-answer performance when reasoning about complex information. RAG techniques ...\n",
      "üîó https://microsoft.github.io/graphrag/\n",
      "\n",
      "üîπ 2. Project GraphRAG: News & features - Microsoft Research\n",
      "üìÑ Redmond opens up to discuss its new tool, which can extract data from unstructured text using large language models. Microsoft's GraphRAG is a new approach to ...\n",
      "üîó https://www.microsoft.com/en-us/research/project/graphrag/news-and-awards/\n",
      "\n",
      "üîπ 3. Graph RAG Explained - by Nir Diamant - DiamantAI\n",
      "üìÑ Graph RAG fixes the limits of regular RAG by finding nodes and edges from a knowledge graph ‚Äì in other words, a web of facts and their links.\n",
      "üîó https://diamantai.substack.com/p/graph-rag-explained\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if isinstance(results, list):\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"üîπ {i}. {r['title']}\")\n",
    "        print(f\"üìÑ {r['snippet']}\")\n",
    "        print(f\"üîó {r['link']}\\n\")\n",
    "else:\n",
    "    print(results)  # In case of error string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8828342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "\n",
    "from tools.wiki_lookup import wiki_lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d4696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Wikipedia Summary:\n",
      " Prompt engineering is the process of structuring or crafting an instruction in order to produce the best possible output from a generative artificial intelligence (AI) model.\n",
      "A prompt is natural language text describing the task that an AI should perform. A prompt for a text-to-text language model can be a query, a command, or a longer statement including context, instructions, and conversation history.\n"
     ]
    }
   ],
   "source": [
    "query = \"Graph RAG\"\n",
    "\n",
    "wiki_summary = wiki_lookup(query, sentences=3)\n",
    "print(\"üìù Wikipedia Summary:\\n\", wiki_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e13e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.tool_selector import tool_selector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fef4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò Source: Wikipedia\n",
      "üìù Result:\n",
      "Prompt engineering is the process of structuring or crafting an instruction in order to produce the best possible output from a generative artificial intelligence (AI) model.\n",
      "A prompt is natural language text describing the task that an AI should perform. A prompt for a text-to-text language model can be a query, a command, or a longer statement including context, instructions, and conversation history.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 120, but your input_length is only 32. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Advancements in RAG: A Comprehensive Survey of Techniques ...\n",
      "üìÑ Recent Advances in Retrieval Techniques ¬∑ Query Optimization ¬∑ Embedding Models ¬∑ Retrieval Sources and Granularity ¬∑ Indexing Optimization ...\n",
      "üîó https://medium.com/@sahin.samia/advancements-in-rag-a-comprehensive-survey-of-techniques-and-applications-b6160b035199\n",
      "\n",
      "üîπ Top 10 RAG Papers from January 2025 - Athina AI Hub\n",
      "üìÑ Top 10 RAG Papers from January 2025 ¬∑ 1) Retrieval-Augmented Generation with Graphs (GraphRAG) ¬∑ 2) MiniRAG: Towards Extremely Simple Retrieval- ...\n",
      "üîó https://hub.athina.ai/top-10-rag-papers-from-january-2025-2/\n",
      "\n",
      "üîπ Latest Developments in Retrieval-Augmented Generation - CelerData\n",
      "üìÑ RAG combines two powerful elements: retrieval mechanisms and generative models. This combination enhances the quality and relevance of generated content.\n",
      "üîó https://celerdata.com/glossary/latest-developments-in-retrieval-augmented-generation\n",
      "\n",
      "üìÑ PDF Summary:\n",
      "[PDF Reader Error] no such file: '../sample_docs/semple.pdf'\n"
     ]
    }
   ],
   "source": [
    "# Wiki\n",
    "res1 = tool_selector(\"Graph RAG\", context_type=\"wiki\")\n",
    "print(f\"üìò Source: {res1['source']}\\nüìù Result:\\n{res1['result']}\\n\")\n",
    "\n",
    "# Web\n",
    "res2 = tool_selector(\"Latest RAG breakthroughs\", context_type=\"web\", api_keys={\"SERPER_API_KEY\": SERPER_API_KEY})\n",
    "if isinstance(res2[\"result\"], list):\n",
    "    for r in res2[\"result\"]:\n",
    "        print(f\"üîπ {r['title']}\\nüìÑ {r['snippet']}\\nüîó {r['link']}\\n\")\n",
    "\n",
    "# PDF\n",
    "res3 = tool_selector(\"N/A\", context_type=\"pdf\", file_path=\"../sample_docs/sample.pdf\")\n",
    "print(f\"üìÑ PDF Summary:\\n{res3['result']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1ab68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Graph RAG is a combination of retrieval-augmented generation and graph reasoning.\n",
      "2. Graph RAG is a combination of retrieval-augmented generation and graph reasoning.\n",
      "3. Graph RAG is a combination of retrieval-augmented generation and graph reasoning.\n"
     ]
    }
   ],
   "source": [
    "from memory.memory_manager import MemoryManager\n",
    "\n",
    "memory = MemoryManager()\n",
    "\n",
    "# Add something\n",
    "memory.add_memory(\"Graph RAG is a combination of retrieval-augmented generation and graph reasoning.\")\n",
    "\n",
    "# Retrieve\n",
    "results = memory.search_memory(\"What is Graph RAG?\")\n",
    "for i, r in enumerate(results, 1):\n",
    "    print(f\"{i}. {r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69bd3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Found relevant memory:\n",
      "1. Graph RAG is a combination of retrieval-augmented generation and graph reasoning.\n",
      "\n",
      "2. Graph RAG is a combination of retrieval-augmented generation and graph reasoning.\n",
      "\n",
      "3. Graph RAG is a combination of retrieval-augmented generation and graph reasoning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from agents.tool_selector import tool_selector\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\")\n",
    "\n",
    "# üîç User query\n",
    "user_query = \"Graph RAG applications in 2024\"\n",
    "\n",
    "# üß† 1. Search memory\n",
    "context = memory.search_memory(user_query)\n",
    "\n",
    "# üõ†Ô∏è 2. If memory insufficient, call tool\n",
    "if len(context) < 2:\n",
    "    response = tool_selector(user_query, context_type=\"wiki\", api_keys={\"SERPER_API_KEY\": SERPER_API_KEY})\n",
    "    print(f\"üîé Using Tool: {response['source']}\")\n",
    "    print(f\"üìÑ Result:\\n{response['result']}\\n\")\n",
    "    \n",
    "    memory.add_memory(response[\"result\"])\n",
    "else:\n",
    "    print(\"üß† Found relevant memory:\")\n",
    "    for i, mem in enumerate(context):\n",
    "        print(f\"{i+1}. {mem}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55202f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
